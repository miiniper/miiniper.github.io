---
layout:     post
title:      felk+kafka
subtitle:   felk+kafka
date:       2019-09-19
author:     hl
header-img: img/bg-mongo.jpg
catalog: true
tags:
    - elk
    - kafka
---



[TOC]

## filebeat + kafka + elk 小结

## 概述

filebeat 收集日志打到kafka，logstash主动消费kafka数据到es，kibana用于展示数据。

## 注意

1. filebeat 对kafka 版本的支持 需要去官方文档查看对应支持的版本。
2. filebeat 占用cpu资源高参数调整：需要调整input：encoding，harvester_buffer_size，max_bytes；output.kafka需要调整：version，worker和compression。版本一定要写kafka对应版本。worker和cpu核数有关。
3. filebeat 多个模块可以加类似tag区分：fields.service
4. filebeat 7.x版本以后不支持filebeat.prospectors字段
5. kafka需要创建和broker相应的倍数的Partition。副本数一般为3个
6. logstash 解析json格式需要在input 加上codec => json {   charset => "UTF-8"}。
7. logstash filter 过滤规则详细需要取官网查看，需要注意的是替换在mutate.gsub中的第一个字段为message。
8. logstash output可根据不同的fields.service打到不通index。
9. es主要参数调整indices.fielddata.cache.size
   indices.breaker.fielddata.limit
   indices.recovery.max_bytes_per_sec
   indices.memory.index_buffer_size
   thread_pool.bulk.queue_size
   thread_pool.index.queue_size
   thread_pool.search.queue_size
10. es如果查询时间跨度大node性能不行的可能会挂掉：升级kernel4.19以上；crontab里写子监控脚本。
11. es 一点要注意jvm内存的使用情况：如果jvm的内存只升不降或者接近99%，立即重启该节点es服务否则集群不工作
12. es分片和副本原则和kafka的原则一样。冷热分离使用index.routing.allocation.exclude._ip字段实现。
13. es模板在/etc/elasticsearch/template目录下。
14. es瓶颈主要在磁盘io所以针对es的数据持久化进行优化(写在模板里)，主要为index.refresh_interval",建议有副本建议30s-60s；index.translog.sync_interval 这个参数是保障数据丢失的时间，实际为刷新磁盘数据。默认为5s，建议60s；index.translog.durability默认request,建议async；index.translog.flush_threshold_size默认512M，这个值和分片的大小有关，如果片数据大将该值调大一般1G-2G，具体还得看片数据大小。index.translog.retention.size和index.translog.retention.age为translog保留大小和时间，一般保持默认512M和12h。

## 详解

### 自检脚本

```
#!/bin/bash
esps=`ps -ef |grep elasticsearch |grep -v grep  |wc -l`
if [ $esps -lt 2 ]
then
  systemctl restart   elasticsearch.service
  echo "restart es "
else
echo "ok"
fi

crontab -e
*/5 * * * * bash /home/cron/escheck.sh > /dev/null 2>&1 &
```



```
补充1：es集群io高和jvm使用高负载高都会影响kafka的数据消费，导致数据消费慢；而且io高会容易降机器跑死，分片会重新relocating，导致集群其他机器负载高，消费会更慢。所以尽量将历史数据减少副本或者删除没用的历史数据，使relocating数减少加快当前消费。

补充2：当集群unassigned_shards数高时最好不要添加新node到集群，也会导致relocating。可以使用cluster.routing.rebalance.enable和cluster.routing.allocation.enable调整。但是在这修改这两哥参数后，如果集群有磁盘损坏并且无副本集群会一直处于red状态（删除red索引解决）。
```



# kafka

## kafka调优注意

1. jvm : export KAFKA_HEAP_OPTS="-Xmx20G -Xms20G"  添加到 kafka-server-start.sh 中，大小为内存的一半。
2. num.network.threads 网络处理的线程数和cpu相关
3. num.io.threads 最好是cpu的倍数，但是不要超过3倍。也和broker的目录数有关
4. log.retention.hours 一般为72小时
5. log.segment.bytes 段文件大小，如果数据量大建议大于1G
6. num.replica.fetchers ,副本复制的形成数，一般3
7. replica.fetch.max.bytes 默认为1M，太小建议改大
8. auto.create.topic.enable ,不建议打开
9. auto.leader.rebalance.enable,自动平衡，建议打开
10. export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MetaspaceSize=96m -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:-HeapDumpOnOutOfMemoryError -XX:+DisableExplicitGC -Djava.awt.headless=true"
11. export JMX_PORT=1099添加到 kafka-server-start.sh 中

